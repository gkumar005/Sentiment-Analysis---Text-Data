{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9HyYTFwRVxk"
   },
   "source": [
    "# Assignment Two:  Sentiment Classification\n",
    "\n",
    "For this exercise you will be using the \"SemEval 2017 task 4\" corpus provided on the module website, available through the following link: https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs918/semeval-tweets.tar.bz2 You will focus particularly on Subtask A, i.e. classifying the overall sentiment of a tweet as positive, negative or neutral.\n",
    "\n",
    "You are requested to produce a standalone Python program or Jupyter notebook for coursework submission. The input to your program is the SemEval data downloaded. Note that TAs need to run your program on their own machine by using the original SemEval data. As such, donâ€™t submit a Python program that takes as input some preprocessed files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lz7pLxlMRVxu"
   },
   "source": [
    "# Important library import\n",
    "You may import more packages here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQORkaCvRVxv",
    "outputId": "b1b1b4e6-fb5a-4233-86cb-e903407c8aa1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/Gaurav/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Gaurav/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Gaurav/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importing all the required packages\n",
    "import re\n",
    "import nltk\n",
    "from io import open\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "lm = nltk.stem.WordNetLemmatizer()\n",
    "tokenizr = TweetTokenizer()\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import  MultinomialNB,GaussianNB,ComplementNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import string, random, time, math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "from os.path import join\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "# Instantiates the device to be used as GPU/CPU based on availability\n",
    "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports all the Machine learning functions\n",
    "from ml_preprocessing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import all the functions/modules from ml_preprocessing file\n",
    "from ml_preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the data sets and Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the path if data is in other directory\n",
    "path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zeTOJHaORVx0"
   },
   "outputs": [],
   "source": [
    "# Load training set and the testing set\n",
    "train_df = pd.read_csv(join('semeval-tweets','twitter-training-data.txt'),\\\n",
    "                       names = ['id','sentiment','text'], sep='\\t', header=None,encoding='utf8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ekN3KmERRVxx"
   },
   "outputs": [],
   "source": [
    "# Define test sets\n",
    "testsets = ['twitter-test1.txt', 'twitter-test2.txt', 'twitter-test3.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Cb-W5nQR5eFN"
   },
   "outputs": [],
   "source": [
    "# Load Glove embeddings\n",
    "embeddings_index={}\n",
    "with open(path+'glove.twitter.27B.100d.txt','r') as f:\n",
    "    for line in f:\n",
    "        values=line.split()\n",
    "        word = values[0]\n",
    "        vectors=np.asarray(values[1:],'float32')\n",
    "        embeddings_index[word]=vectors\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeleton: Evaluation code for the test sets\n",
    "def read_test(testset):\n",
    "    '''\n",
    "    readin the testset and return a dictionary\n",
    "    :param testset: str, the file name of the testset to compare\n",
    "    '''\n",
    "    id_gts = {}\n",
    "    with open(testset, 'r', encoding='utf8') as fh:\n",
    "        for line in fh:\n",
    "            fields = line.split('\\t')\n",
    "            tweetid = fields[0]\n",
    "            gt = fields[1]\n",
    "\n",
    "            id_gts[tweetid] = gt\n",
    "\n",
    "    return id_gts\n",
    "\n",
    "\n",
    "def confusion(id_preds, testset, classifier):\n",
    "    '''\n",
    "    print the confusion matrix of {'positive', 'netative'} between preds and testset\n",
    "    :param id_preds: a dictionary of predictions formated as {<tweetid>:<sentiment>, ... }\n",
    "    :param testset: str, the file name of the testset to compare\n",
    "    :classifier: str, the name of the classifier\n",
    "    '''\n",
    "    id_gts = read_test(testset)\n",
    "\n",
    "    gts = []\n",
    "    for m, c1 in id_gts.items():\n",
    "        if c1 not in gts:\n",
    "            gts.append(c1)\n",
    "\n",
    "    gts = ['positive', 'negative', 'neutral']\n",
    "\n",
    "    conf = {}\n",
    "    for c1 in gts:\n",
    "        conf[c1] = {}\n",
    "        for c2 in gts:\n",
    "            conf[c1][c2] = 0\n",
    "\n",
    "    for tweetid, gt in id_gts.items():\n",
    "        if tweetid in id_preds:\n",
    "            pred = id_preds[tweetid]\n",
    "        else:\n",
    "            pred = 'neutral'\n",
    "        conf[pred][gt] += 1\n",
    "\n",
    "    print(''.ljust(12) + '  '.join(gts))\n",
    "\n",
    "    for c1 in gts:\n",
    "        print(c1.ljust(12), end='')\n",
    "        for c2 in gts:\n",
    "            if sum(conf[c1].values()) > 0:\n",
    "                print('%.3f     ' % (conf[c1][c2] / float(sum(conf[c1].values()))), end='')\n",
    "            else:\n",
    "                print('0.000     ', end='')\n",
    "        print('')\n",
    "\n",
    "    print('')\n",
    "\n",
    "\n",
    "def evaluate(id_preds, testset, classifier):\n",
    "    '''\n",
    "    print the macro-F1 score of {'positive', 'netative'} between preds and testset\n",
    "    :param id_preds: a dictionary of predictions formated as {<tweetid>:<sentiment>, ... }\n",
    "    :param testset: str, the file name of the testset to compare\n",
    "    :classifier: str, the name of the classifier\n",
    "    '''\n",
    "    id_gts = read_test(testset)\n",
    "\n",
    "    acc_by_class = {}\n",
    "    for gt in ['positive', 'negative', 'neutral']:\n",
    "        acc_by_class[gt] = {'tp': 0, 'fp': 0, 'tn': 0, 'fn': 0}\n",
    "\n",
    "    catf1s = {}\n",
    "\n",
    "    ok = 0\n",
    "    for tweetid, gt in id_gts.items():\n",
    "        if tweetid in id_preds:\n",
    "            pred = id_preds[tweetid]\n",
    "        else:\n",
    "            pred = 'neutral'\n",
    "\n",
    "        if gt == pred:\n",
    "            ok += 1\n",
    "            acc_by_class[gt]['tp'] += 1\n",
    "        else:\n",
    "            acc_by_class[gt]['fn'] += 1\n",
    "            acc_by_class[pred]['fp'] += 1\n",
    "\n",
    "    catcount = 0\n",
    "    itemcount = 0\n",
    "    macro = {'p': 0, 'r': 0, 'f1': 0}\n",
    "    micro = {'p': 0, 'r': 0, 'f1': 0}\n",
    "    semevalmacro = {'p': 0, 'r': 0, 'f1': 0}\n",
    "\n",
    "    microtp = 0\n",
    "    microfp = 0\n",
    "    microtn = 0\n",
    "    microfn = 0\n",
    "    for cat, acc in acc_by_class.items():\n",
    "        catcount += 1\n",
    "\n",
    "        microtp += acc['tp']\n",
    "        microfp += acc['fp']\n",
    "        microtn += acc['tn']\n",
    "        microfn += acc['fn']\n",
    "\n",
    "        p = 0\n",
    "        if (acc['tp'] + acc['fp']) > 0:\n",
    "            p = float(acc['tp']) / (acc['tp'] + acc['fp'])\n",
    "\n",
    "        r = 0\n",
    "        if (acc['tp'] + acc['fn']) > 0:\n",
    "            r = float(acc['tp']) / (acc['tp'] + acc['fn'])\n",
    "\n",
    "        f1 = 0\n",
    "        if (p + r) > 0:\n",
    "            f1 = 2 * p * r / (p + r)\n",
    "\n",
    "        catf1s[cat] = f1\n",
    "\n",
    "        n = acc['tp'] + acc['fn']\n",
    "\n",
    "        macro['p'] += p\n",
    "        macro['r'] += r\n",
    "        macro['f1'] += f1\n",
    "\n",
    "        if cat in ['positive', 'negative']:\n",
    "            semevalmacro['p'] += p\n",
    "            semevalmacro['r'] += r\n",
    "            semevalmacro['f1'] += f1\n",
    "\n",
    "        itemcount += n\n",
    "\n",
    "    micro['p'] = float(microtp) / float(microtp + microfp)\n",
    "    micro['r'] = float(microtp) / float(microtp + microfn)\n",
    "    micro['f1'] = 2 * float(micro['p']) * micro['r'] / float(micro['p'] + micro['r'])\n",
    "\n",
    "    semevalmacrof1 = semevalmacro['f1'] / 2\n",
    "\n",
    "    print(testset + ' (' + classifier + '): %.3f' % semevalmacrof1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenoze and basic preprocessing of the text\n",
    "def toknz_lematz(twts):\n",
    "    negation = ['not','no','nor']\n",
    "    stop = list(set(stopwords.words('english'))-set(negation))\n",
    "    tk_men_words = [lm.lemmatize(words) for words in tokenizr.tokenize((twts)) if words not in stop]\n",
    "    return tk_men_words\n",
    "\n",
    "def txt_preprocessor(twts):\n",
    "  \n",
    "    # remocve hashtags and users marked\n",
    "    story = re.sub(r\"[@0-9](\\w+)\", \"\",twts)\n",
    "    # # remove links\n",
    "    story = re.sub(r\"\\b(https?)[\\w/.:?$@!]+\\b\", \"\", story)\n",
    "    # remove punct or special character\n",
    "    story = re.sub(r\"[^A-Za-z0-9 ]\", \"\", story)\n",
    "    # remove all words with numbers\n",
    "    story = re.sub(r'\\w*\\d\\w*', '', story)\n",
    "    # # remove single digits\n",
    "    story = re.sub(r\"\\b\\d+\\b\", \"\", story)\n",
    "    # #remove single word character\n",
    "    story = re.sub(r\"\\b\\w\\b\", \"\", story)\n",
    "    # tokenize lemmatize\n",
    "    story_1 = toknz_lematz(story.lower())\n",
    "  \n",
    "    return story_1\n",
    "\n",
    "def clean_df(df):\n",
    "    df['cln_twts'] = df['text'].apply(lambda x: txt_preprocessor(x))\n",
    "    df['flag']=df['cln_twts'].apply(lambda x : len(x))\n",
    "    df = df[df.flag > 0]\n",
    "    df = df.sort_values(by=['flag']).reset_index() \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_idx(word,vocab_dict): # provide index of all the words from word to index mapping dictionary(vocab_dict)\n",
    "    try :\n",
    "        return vocab_dict[word]\n",
    "    except:\n",
    "        return vocab_dict['<unknown>'] # if word not found provide index of unknown word.\n",
    "    \n",
    "# creates a list of tensors(with word index) of all the tweets of the training set\n",
    "def data_preprocess_embed(df,vocab_dict):\n",
    "    df['twt_idx'] = df.cln_twts.apply(lambda x: [word_idx(i,vocab_dict) for i in x])\n",
    "    tensor_ls = [torch.LongTensor(i) for i in df['twt_idx'].values]\n",
    "    return tensor_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_encode(sentiment): # encodes all the sentiments in the data as the mapping given\n",
    "    sentmnt_map = {'negative': 0,'neutral': 1,'positive' : 2}\n",
    "    return sentmnt_map[sentiment]\n",
    "def y_decode(value): # encodes all the sentiments in the data as the mapping given\n",
    "    value_sentiment_map = {0:'negative', 1:'neutral', 2:'positive'}\n",
    "    return value_sentiment_map[value]\n",
    "    \n",
    "def batch_sentiments_vec(sentiments): # return encoded sentiment array of a batch\n",
    "    batch_sntmnt_rep = torch.zeros([len(sentiments)], dtype=torch.long)\n",
    "    for index, sentiment in enumerate(sentiments):\n",
    "        batch_sntmnt_rep[index] = y_encode(sentiment)\n",
    "    return batch_sntmnt_rep\n",
    "# return a batch of data on which model trains\n",
    "def batched_dataloader_n(i,n_points,df,matrix_idx, device = 'cpu'):\n",
    "    x = matrix_idx[i:i+n_points]#.to(device)\n",
    "    y = batch_sentiments_vec(df.loc[i:i+n_points-1,'sentiment'].values).to(device)\n",
    "    leng = list(df.loc[i:i+n_points-1,'flag'].values)\n",
    "    return  x,y,leng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data and returns clean dataframe, \n",
    "# Also returns indexed tensor array of each row of a dataframe\n",
    "# selects best 5000 vocabs, and returns embedding matrix along with word to index mapping dictionary\n",
    "def lstm_preprocsr(df,dataset_type): \n",
    "    \n",
    "    if dataset_type == 'train' :   \n",
    "        train_df = clean_df(df) # cleans train_data\n",
    "        # sub-sampling of the neutral data based on random index\n",
    "        ax1 = train_df[train_df.sentiment == 'neutral'].index\n",
    "        ax2 = random.sample(range(0, len(ax1)), int(0.7*len(ax1)))\n",
    "        pos_idx = train_df[train_df.sentiment == 'positive'].index\n",
    "        neg_idx = train_df[train_df.sentiment == 'negative'].index\n",
    "\n",
    "        req_idx = list(pos_idx) + list(neg_idx)\n",
    "        for i in ax2:\n",
    "            req_idx.append(ax1[i])\n",
    "\n",
    "        train_df = train_df[train_df.index.isin(req_idx)].reset_index(drop=True)\n",
    "        \n",
    "        # create vocab on the basic of frequency in all the sentimetns sentiments then merge them.\n",
    "        neg_vocab = [j for i in train_df[train_df.sentiment == 'negative'].\\\n",
    "                     cln_twts.values for j in i if j in embeddings_index.keys() and len(j)>1]\n",
    "        neu_vocab = [j for i in train_df[train_df.sentiment == 'neutral'].\\\n",
    "                     cln_twts.values for j in i if j in embeddings_index.keys() and len(j)>1]\n",
    "        pos_vocab = [j for i in train_df[train_df.sentiment == 'positive'].\\\n",
    "                     cln_twts.values for j in i if j in embeddings_index.keys() and len(j)>1]\n",
    "        \n",
    "        # logic to get 5000 vocab size based on inverse proportion of sentiments\n",
    "        random_n = 10000\n",
    "        for i in range(1000):  \n",
    "            #negative vocab\n",
    "            neg_count_tup = Counter(neg_vocab).most_common(int(random_n*0.40))\n",
    "            neg_frequent_words = list(pd.DataFrame(neg_count_tup, columns = ['word','coun']).word.values)\n",
    "            required_words = neg_frequent_words[20:]\n",
    "            #neutral vocabs\n",
    "            neu_count_tup = Counter(neu_vocab).most_common(int(random_n*0.30))\n",
    "            neu_frequent_words = list(pd.DataFrame(neu_count_tup, columns = ['word','coun']).word.values)\n",
    "            required_words += neu_frequent_words[20:]\n",
    "            # positive vocabs    \n",
    "            pos_count_tup = Counter(pos_vocab).most_common(int(random_n*0.31))\n",
    "            pos_frequent_words = list(pd.DataFrame(pos_count_tup, columns = ['word','coun']).word.values)\n",
    "            required_words += pos_frequent_words[20:]\n",
    "            \n",
    "            final_count = len(set(required_words))\n",
    "            if final_count < 5000:\n",
    "                random_n += 0.5\n",
    "            elif final_count > 5000: \n",
    "                random_n -= 0.5\n",
    "            else: break\n",
    "        # final vocab list \"required_words\"\n",
    "        \n",
    "        # based on final vocab list creates embedding matrix\n",
    "        #print(len(set(required_words)))\n",
    "        vocab_ls = set(required_words)\n",
    "        embedding_matrix = np.zeros((len(vocab_ls)+2,100))\n",
    "        vocab_dict = {}\n",
    "        vocab_dict['<pad>'] = 0\n",
    "        vocab_dict['<unknown>'] = 1\n",
    "\n",
    "        unk_word_embd = np.random.rand(100)\n",
    "        embedding_matrix[1] = unk_word_embd\n",
    "\n",
    "        for idx,word in enumerate(vocab_ls):\n",
    "            vocab_dict[word] = idx+2\n",
    "            embedding_matrix[idx+2] = embeddings_index[word]\n",
    "\n",
    "        train_matrix_df = data_preprocess_embed(train_df,vocab_dict)\n",
    "        \n",
    "    return train_df,train_matrix_df,embedding_matrix,vocab_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self,vocab_size, input_size, hidden_size, output_size,device):\n",
    "        super(LSTM_net, self).__init__()\n",
    "        self.device=device\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, input_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n",
    "        \n",
    "        self.lstm_cell = nn.LSTM(input_size, hidden_size,batch_first=False)\n",
    "        \n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input,lengths, hidden = None):\n",
    "        # padded the batch data\n",
    "        input_pad = pad_sequence(input).to(self.device).permute(1,0) \n",
    "        embedded = self.embedding(input_pad).transpose(0, 1)\n",
    "        # pack padded the output of padded data\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, lengths,enforce_sorted = False)\n",
    "        out, hidden = self.lstm_cell(packed, hidden)\n",
    "        \n",
    "        output = self.h2o(hidden[0].view(-1, self.hidden_size))\n",
    "\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains the network for a batch and return the training loss for visuallization.\n",
    "def train_batch(net,lstm_train_df,lstm_train_matrix_idx, opt, criterion, n_points, device = 'cpu'):\n",
    "    \n",
    "    net.train().to(device)\n",
    "    loss_training = 0\n",
    "    \n",
    "    for i in range(0,len(lstm_train_df)-n_points,n_points): \n",
    "        opt.zero_grad()\n",
    "        #batch_x, batch_y = batched_dataloader(i, n_points, train_df , device)\n",
    "        batch_x, batch_y,batch_lengths = batched_dataloader_n(i, n_points ,lstm_train_df,lstm_train_matrix_idx ,device)\n",
    "        if len(batch_x)>0:\n",
    "            output, hidden = net(batch_x,batch_lengths)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss_training += loss.item()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        else:\n",
    "            continue\n",
    "    return  loss_training/len(lstm_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes prediction on the test data.\n",
    "def lstm_predictor(net, df,df_matrix, device = 'cpu'):\n",
    "    net = net.eval().to(device)\n",
    "    batch_test_x,batch_test_y,batch_lengths = batched_dataloader_n(0,len(df), df,df_matrix, device)\n",
    "    output,hidden = net(batch_test_x,batch_lengths)\n",
    "    actuals = batch_test_y.cpu().detach().numpy()\n",
    "    pred = torch.argmax(output,dim=1).cpu().detach().numpy()      \n",
    "    return pred,actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains the entire network for n number of epochs\n",
    "def train_LSTM(net,lstm_train_df,lstm_train_matrix_idx, lr = 0.01, n_batches = 100, batch_size = 10, display_freq=5, device = 'cpu'):\n",
    "    net = net.to(device)\n",
    "    net.embedding.weight.requires_grad = unfrozen = False\n",
    "    criterion = nn.NLLLoss()\n",
    "    opt = optim.Adam(net.parameters(), lr=lr,betas = (0.99,0.99))\n",
    "    \n",
    "    loss_arr = np.zeros(n_batches + 1)\n",
    "    for i in range(n_batches):\n",
    "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net,lstm_train_df,lstm_train_matrix_idx, opt, criterion, batch_size, device))/(i + 1)\n",
    "        \n",
    "#         if i%display_freq == display_freq-1:\n",
    "#             clear_output(wait=True)\n",
    "#             print('Iteration', i, 'Loss', loss_arr[i])\n",
    "#             plt.figure()\n",
    "#             plt.plot(loss_arr[1:i], '-*')\n",
    "#             plt.xlabel('Iteration')\n",
    "#             plt.ylabel('Loss')\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoGPMQoVRVx0"
   },
   "source": [
    "# Building All Classifiers\n",
    "You need to create your own classifiers (at least 3 classifiers). For each classifier, you can choose between the bag-of-word features and the word-embedding-based features. Each classifier has to be evaluated over 3 test sets. Make sure your classifier produce consistent performance across the test sets. Marking will be based on the performance over all 5 test sets (2 of them are not provided to you)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate classifiers,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "qHX18FiRRVxx"
   },
   "outputs": [],
   "source": [
    "# given the predictions and the actuals it prints confusion matrix and macroaveraged f1-score\n",
    "# def evaluate(prediction,ground_truth,features,classifier,i):\n",
    "    \n",
    "#     confusion_matrix = metrics.confusion_matrix(ground_truth,prediction)\n",
    "#     f1_score = metrics.f1_score(ground_truth,prediction, average=None)\n",
    "    \n",
    "#     f1_neg_pos = (f1_score[0]+f1_score[2])/2\n",
    "#     print(f\"Evaluation {classifier} and {features} for Test{i+1} dataset\")\n",
    "#     print(\"-consusion_matrix: \\n\",confusion_matrix)\n",
    "#     print(f\"-f1score macroavg(pos&neg): {f1_neg_pos}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "NITOR3vPRVx1",
    "outputId": "a19ef9dc-8858-497c-a3f8-b09ff4804ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM with CountVectorizer\n",
      "semeval-tweets/twitter-test1.txt (CountVectorizer-SVM): 0.438\n",
      "semeval-tweets/twitter-test2.txt (CountVectorizer-SVM): 0.441\n",
      "semeval-tweets/twitter-test3.txt (CountVectorizer-SVM): 0.421\n",
      "Training SVM with TFIDF\n",
      "semeval-tweets/twitter-test1.txt (TFIDF-SVM): 0.316\n",
      "semeval-tweets/twitter-test2.txt (TFIDF-SVM): 0.330\n",
      "semeval-tweets/twitter-test3.txt (TFIDF-SVM): 0.290\n",
      "Training SVM with Glove\n",
      "semeval-tweets/twitter-test1.txt (Glove-SVM): 0.438\n",
      "semeval-tweets/twitter-test2.txt (Glove-SVM): 0.466\n",
      "semeval-tweets/twitter-test3.txt (Glove-SVM): 0.476\n",
      "Training Naive Bayes with CountVectorizer\n",
      "semeval-tweets/twitter-test1.txt (CountVectorizer-Naive Bayes): 0.500\n",
      "semeval-tweets/twitter-test2.txt (CountVectorizer-Naive Bayes): 0.531\n",
      "semeval-tweets/twitter-test3.txt (CountVectorizer-Naive Bayes): 0.492\n",
      "Training Naive Bayes with TFIDF\n",
      "semeval-tweets/twitter-test1.txt (TFIDF-Naive Bayes): 0.360\n",
      "semeval-tweets/twitter-test2.txt (TFIDF-Naive Bayes): 0.405\n",
      "semeval-tweets/twitter-test3.txt (TFIDF-Naive Bayes): 0.358\n",
      "Multinomial NB doesn't work with negative feature vec \n",
      "Training Compliment NB with CountVectorizer\n",
      "semeval-tweets/twitter-test1.txt (CountVectorizer-Compliment NB): 0.542\n",
      "semeval-tweets/twitter-test2.txt (CountVectorizer-Compliment NB): 0.547\n",
      "semeval-tweets/twitter-test3.txt (CountVectorizer-Compliment NB): 0.532\n",
      "Training Compliment NB with TFIDF\n",
      "semeval-tweets/twitter-test1.txt (TFIDF-Compliment NB): 0.545\n",
      "semeval-tweets/twitter-test2.txt (TFIDF-Compliment NB): 0.560\n",
      "semeval-tweets/twitter-test3.txt (TFIDF-Compliment NB): 0.536\n",
      "Compliment NB doesn't work with negative feature vec \n",
      "Training Gaussian NB with CountVectorizer\n",
      "semeval-tweets/twitter-test1.txt (CountVectorizer-Gaussian NB): 0.483\n",
      "semeval-tweets/twitter-test2.txt (CountVectorizer-Gaussian NB): 0.506\n",
      "semeval-tweets/twitter-test3.txt (CountVectorizer-Gaussian NB): 0.464\n",
      "Training Gaussian NB with TFIDF\n",
      "semeval-tweets/twitter-test1.txt (TFIDF-Gaussian NB): 0.494\n",
      "semeval-tweets/twitter-test2.txt (TFIDF-Gaussian NB): 0.515\n",
      "semeval-tweets/twitter-test3.txt (TFIDF-Gaussian NB): 0.483\n",
      "Training Gaussian NB with Glove\n",
      "semeval-tweets/twitter-test1.txt (Glove-Gaussian NB): 0.514\n",
      "semeval-tweets/twitter-test2.txt (Glove-Gaussian NB): 0.516\n",
      "semeval-tweets/twitter-test3.txt (Glove-Gaussian NB): 0.506\n",
      "Training LSTM with Glove\n",
      "semeval-tweets/twitter-test1.txt (Glove-LSTM): 0.606\n",
      "semeval-tweets/twitter-test2.txt (Glove-LSTM): 0.637\n",
      "semeval-tweets/twitter-test3.txt (Glove-LSTM): 0.599\n"
     ]
    }
   ],
   "source": [
    "# Note:  All the ML based functions are getting pulled from ml_preprocessing file\n",
    "# Didn't include in this code to make it look a bit clean.\n",
    "for classifier in ['SVM', 'Naive Bayes','Compliment NB','Gaussian NB','LSTM']:\n",
    "    for features in ['CountVectorizer', 'TFIDF','Glove']:\n",
    "        dataset_type = 'train'\n",
    "        \n",
    "        if classifier == 'SVM':\n",
    "            X,Y,feat_vect = preprocessor(train_df,classifier,features,dataset_type)\n",
    "\n",
    "            print(f\"Training {classifier} with {features}\")\n",
    "            clf = model_trainer(X,Y,classifier)\n",
    "\n",
    "\n",
    "        elif classifier == 'Naive Bayes':\n",
    "            X,Y,feat_vect = preprocessor(train_df,classifier,features,dataset_type)\n",
    "\n",
    "            if features != 'Glove':\n",
    "                print(f\"Training {classifier} with {features}\")\n",
    "                clf = model_trainer(X,Y,classifier)\n",
    "            else :\n",
    "                print(\"Multinomial NB doesn't work with negative feature vec \")\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "        elif classifier == 'Compliment NB':\n",
    "            X,Y,feat_vect = preprocessor(train_df,classifier,features,dataset_type)\n",
    "            if features != 'Glove':\n",
    "                print(f\"Training {classifier} with {features}\")\n",
    "                clf = model_trainer(X,Y,classifier)\n",
    "            else :\n",
    "                print(\"Compliment NB doesn't work with negative feature vec \")\n",
    "                continue\n",
    "\n",
    "\n",
    "        elif classifier == 'Gaussian NB':\n",
    "            X,Y,feat_vect = preprocessor(train_df,classifier,features,dataset_type)\n",
    "            print(f\"Training {classifier} with {features}\")\n",
    "            clf = model_trainer(X,Y,classifier)\n",
    "\n",
    "\n",
    "\n",
    "        elif classifier == 'LSTM':\n",
    "            if features == 'Glove':\n",
    "                print(f\"Training {classifier} with {features}\")\n",
    "                # preprocessing\n",
    "                lstm_train_df,lstm_train_matrix_idx,embedding_matrix,vocab_dict = lstm_preprocsr(train_df,dataset_type)\n",
    "                hidden_layer_size = 64\n",
    "                word_vector_size = 100\n",
    "                distnct_sntmtn = 3\n",
    "                \n",
    "                net = LSTM_net(embedding_matrix.shape[0],embedding_matrix.shape[1], hidden_layer_size, distnct_sntmtn,device_gpu)\n",
    "                train_LSTM(net,lstm_train_df,lstm_train_matrix_idx, lr=0.0001, n_batches=30, batch_size = 64, display_freq=1, device = device_gpu)\n",
    "            else: continue\n",
    "        else:\n",
    "            print('Unknown classifier name' + classifier)\n",
    "            continue\n",
    "\n",
    "        # Predition performance of thez classifiers\n",
    "        for testset in testsets:\n",
    "            dataset_type = 'test'\n",
    "            \n",
    "            testset_name = testset\n",
    "            testset_path = join('semeval-tweets', testset_name)\n",
    "            test_df = pd.read_csv(testset_path, names = ['id','sentiment','text'], \n",
    "                                  sep='\\t', header=None,encoding='utf-8')\n",
    "           \n",
    "\n",
    "            if classifier != \"LSTM\":\n",
    "                prediction,ground_truth = predictor(test_df,clf,feat_vect,classifier,features,dataset_type)\n",
    "\n",
    "            else:\n",
    "                \n",
    "                test_df = clean_df(test_df)\n",
    "                test_matrix_idx = data_preprocess_embed(test_df,vocab_dict)\n",
    "                prediction,ground_truth = lstm_predictor(net,test_df,test_matrix_idx,device_gpu)\n",
    "            \n",
    "            prediction_in_sentiment = [y_decode(i) for i in prediction]\n",
    "            tweed_id = ['{0:0>18}'.format(i) for i in test_df.id.values]\n",
    "            id_preds = dict(zip(tweed_id,prediction_in_sentiment))\n",
    "\n",
    "            #evaluate(prediction,ground_truth,features,classifier,i)\n",
    "            evaluate(id_preds, testset_path, features + '-' + classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cs918_assignment_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
